{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29110164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc298b7c",
   "metadata": {},
   "source": [
    "As the world becomes more and more interconnected, air travel becomes an ever more important means of transit for the United States. Despite this importance, U.S. flight delays have become more numerous and unpredictable, exacerbated by the recent pandemics, supply chain disruptions, and climate change. In order to help guide America's future aviation, it is essential that we be able to monitor and predict flight delays. And in order to do this, scienctists and statisticians need access to a large, high quality collection of relevant data.\n",
    "\n",
    "Hoping to address this need, the Bureau of Transportation Statistics, or BTS, has maintained an up-to-date dataset of information on every flight in America that it believes will help researchers and professionals track and predict flight delays. This dataset of [Carrier On-Time Performance](https://www.transtats.bts.gov/tables.asp?qo_vq=EFD&QO_anzr=) contains data dating back to 1987 and aims to document all the information that could relevant to those seeking to model flight delays. However, the BTS is always seeking to improve its data collection. A cursory look through this database will reveal the fact that information for each flight is not always collected in a complete state and numerous additional columns of data have been added over the years.\n",
    "\n",
    "In order to maximize the efficiency of its data collection, the BTS aims to prioritize the most important data columns to ensure that future models are as accurate as possible.\n",
    "\n",
    "The purpose of this project is to create a predictive model of U.S. flight delays with the BTS dataset and identify the data columns that are most important to the model's predictions to help guide the BTS' future data collection efforts and create the best models of American flight delays possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f33f70d",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ff0688",
   "metadata": {},
   "source": [
    "In order to accompilish this, we will using a dataset comprised of the BTS' flight delay records from November 2021 to October 2022. This span of time allows a full year's worth of up-to-date information to be used while minimizing the size of the dataset that will need to be processed by our model (Due to computer memory limitations) and avoiding training our model on the anomalous aviation time period that occured at the beginning of the Covid-19 pandemic.\n",
    "\n",
    "Due to the fact that the BTS only provides data in one month increments, we will need to begin by taking the 12 files of data from each month and combining them into a single dataset for use in our modelling efforts.\n",
    "\n",
    "The following two code cells automatically unpack our zipped folders of raw data and combine them into a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531d446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_zipped_data(root_data_folder_path):\n",
    "    '''\n",
    "    This function opens all zip files in a given folder and combines any csv data found\n",
    "    within them into a single Pandas DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    root_data_folder_path: A string containing the path to a folder containing zip files\n",
    "                           with csv data.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A Pandas Dataframe with all csv data found in the given folder, combined together along\n",
    "    the index (0) axis.\n",
    "    '''\n",
    "    # Creating empty list of DataFrames\n",
    "    data_to_combine = []\n",
    "    # Looping through raw data folder\n",
    "    with os.scandir(root_data_folder_path) as root_data_folder:\n",
    "        total_files = len(os.listdir(root_data_folder_path))\n",
    "        current_progress = 0\n",
    "        for entry in root_data_folder:\n",
    "            # Displaying current progress\n",
    "            current_progress += 1\n",
    "            print(f\"Processing file {current_progress}/{total_files} ...\", end=\"\\r\")\n",
    "            # Searching for zipped data\n",
    "            if entry.name.endswith(\".zip\") and entry.is_file():\n",
    "                # Opening zipped data folders\n",
    "                with zipfile.ZipFile(root_data_folder_path + '/' + entry.name, \"r\") as zipped:\n",
    "                    for name in zipped.namelist():\n",
    "                        # Searching for csv files in zipped folders\n",
    "                        if name.endswith('.csv'):\n",
    "                            with zipped.open(name) as delay_data:\n",
    "                                # Reading csv and adding to list of datasets\n",
    "                                data_to_combine.append(pd.read_csv(delay_data, low_memory=False))\n",
    "    print('All files unpacked. Combining data...', end='\\r')\n",
    "    combined_data = pd.concat(data_to_combine)\n",
    "    print('Data successfully combined!           ')\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab5cee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully combined!           \n"
     ]
    }
   ],
   "source": [
    "delay_df = combine_zipped_data('./raw_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f633eb0b",
   "metadata": {},
   "source": [
    "Before we can begin training a model to predict flight delays using the BTS's data, we must first ensure that the dataset is in good condition. Datasets frequently have missing values, unexpected data types, or erroneous entries that can prevent a model from being trained on it or adversely affect the model's predictive ability. Given the immense scale of the BTS's data, we should expect some of it to contain these issues.\n",
    "\n",
    "In order to combat this, the dataset should be exhaustively cleaned before we attempt to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffec0f9d",
   "metadata": {},
   "source": [
    "### Cleaning Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7741a17b",
   "metadata": {},
   "source": [
    "Missing values, or `NaN`s, are placeholder values in a dataset that typically indicate the absence of data. It is very common for larger or more informal datasets to contain a significant quantity of `NaN`s. This poses an issue for our modelling efforts, as the vast majority of models cannot interpret `NaN` values in their training data. Consequently, the presence of any `NaN` values in our training dataset would prevent us from using it to train a flight delay predictor. As such, it is essential that we remove or replace these `NaN` values before continuing.\n",
    "\n",
    "In order to determine how best to proceed, we can begin by inspecting the dataset to see how many `NaN` values are in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18b865d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                      0\n",
       "Quarter                   0\n",
       "Month                     0\n",
       "DayofMonth                0\n",
       "DayOfWeek                 0\n",
       "                     ...   \n",
       "Div5TotalGTime      6725064\n",
       "Div5LongestGTime    6725064\n",
       "Div5WheelsOff       6725064\n",
       "Div5TailNum         6725064\n",
       "Unnamed: 109        6725064\n",
       "Length: 110, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the nummber of NaNs in a small subset of the data's columns\n",
    "delay_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0890b42b",
   "metadata": {},
   "source": [
    "In this small sample of columns from the dataset, we can see that some columns contain a monstrously large number number of `NaN` values. To understand just how much of each column is a `NaN` value, we can compare it to the number of rows in the dataset, shown by the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d50ff29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6725064"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the number of rows in the dataset for comparison to the number of NaNs\n",
    "delay_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90706d11",
   "metadata": {},
   "source": [
    "In comparing the above number to the `NaN`s in the columns shown previously, we can see that _all_ the values in some columns are `NaN`.\n",
    "\n",
    "This is because some of the columns contain information about flights that were diverted, with information for up to five diversions. Since the vast majority of flights are not diverted even once, let alone five times, these columns are almost always not applicable and thus contain `NaN` values.\n",
    "\n",
    "When faced with `NaN` values, there are three general approaches that can be taken. If the column of data is not vital to our modelling purposes, then we can simply drop columns with `NaN`s. Similarly, if `NaN` values are randomly distributed throughout the rows of data, then we can remove rows of data that contain `NaN` values without misrepresenting the distribution that the dataset was pulled from. And lastly, we can attempt to replace, or impute, these missing values with our best estimate of the values that should be there.\n",
    "\n",
    "Looking at our dataset, we can see that the the columns that have many `NaN`s are not only nearly devoid of data, they also contain information that is not relevant to our attempts to preemptively predict flight delays, such as information on diverted flights. For that reason, we can safely drop the columns that contain a large proportion of `NaN` values. This is accomplished in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6da6137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing all columns that are more than 5% NaN values \n",
    "delay_df = delay_df[delay_df.columns[delay_df.isna().sum() < delay_df.shape[0] / 20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429957c1",
   "metadata": {},
   "source": [
    "The columns with smaller amounts of `NaN` values however, cannot be so easily discarded. A quick inspection of the remaining columns that contain `NaN`s reveals why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88d6fa26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tail_Number', 'DepTime', 'DepDelay', 'DepDelayMinutes', 'DepDel15',\n",
       "       'DepartureDelayGroups', 'TaxiOut', 'WheelsOff', 'WheelsOn', 'TaxiIn',\n",
       "       'ArrTime', 'ArrDelay', 'ArrDelayMinutes', 'ArrDel15',\n",
       "       'ArrivalDelayGroups', 'ActualElapsedTime', 'AirTime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting columns with less than 5% NaNs\n",
    "delay_df.columns[delay_df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73517782",
   "metadata": {},
   "source": [
    "In this list of columns with `NaN`s, we can see the column `ArrDel15` which indicates whether or not a flight's arrival is officially considered delayed by the BTS. This is our delay prediction model's target variable. This is the value it is attempting to predict.\n",
    "\n",
    "Supervised machine learning, like the type we must perform to create a flight delay predictor, relies on the presence of labels that the model can train on in order to determine what each data point in its training data is. Data that does not contain a label value therefore cannot be used for model training.\n",
    "\n",
    "To resolve this issue, we have the option of either dropping any rows that contain these values or replacing them with an estimate such as the median or mode of the dataset's labels. Dropping rows will introduce inaccuracies into our training data if the rows that are removed are not similar to the rows of data that were kept. Replacing these values can also similarly misrepresent the data if the labels do now follows the simple estimator that we use to do the replacing.\n",
    "\n",
    "In order to decide how best to approach this, we can inspect the data with missing labels to see if it greatly differs from the remainder of the dataset.\n",
    "\n",
    "We can begin by inspecting the proportion of flights from each state that have `NaN` delay values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acd904a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delaware                                          0.093750\n",
       "U.S. Virgin Islands                               0.061710\n",
       "Maine                                             0.051497\n",
       "New Jersey                                        0.049989\n",
       "New York                                          0.043800\n",
       "Vermont                                           0.042594\n",
       "Rhode Island                                      0.040019\n",
       "North Dakota                                      0.039498\n",
       "New Hampshire                                     0.037846\n",
       "Virginia                                          0.035908\n",
       "Connecticut                                       0.035568\n",
       "Massachusetts                                     0.035545\n",
       "Alaska                                            0.034058\n",
       "West Virginia                                     0.033224\n",
       "Wyoming                                           0.033012\n",
       "Florida                                           0.032415\n",
       "Ohio                                              0.032113\n",
       "South Carolina                                    0.031066\n",
       "Maryland                                          0.030212\n",
       "Kentucky                                          0.029762\n",
       "Puerto Rico                                       0.028831\n",
       "North Carolina                                    0.028713\n",
       "Indiana                                           0.028459\n",
       "Pennsylvania                                      0.028014\n",
       "Missouri                                          0.027905\n",
       "Illinois                                          0.027523\n",
       "Texas                                             0.026347\n",
       "Tennessee                                         0.025699\n",
       "Colorado                                          0.025403\n",
       "South Dakota                                      0.024707\n",
       "Oklahoma                                          0.024022\n",
       "Alabama                                           0.023358\n",
       "Wisconsin                                         0.023218\n",
       "Kansas                                            0.022964\n",
       "Iowa                                              0.022629\n",
       "Arkansas                                          0.022528\n",
       "Michigan                                          0.022433\n",
       "Louisiana                                         0.022136\n",
       "Nebraska                                          0.021516\n",
       "Washington                                        0.019836\n",
       "Nevada                                            0.018919\n",
       "California                                        0.017894\n",
       "Minnesota                                         0.017811\n",
       "Arizona                                           0.017704\n",
       "Georgia                                           0.017139\n",
       "New Mexico                                        0.017063\n",
       "Mississippi                                       0.016827\n",
       "Oregon                                            0.016784\n",
       "Montana                                           0.016760\n",
       "Idaho                                             0.013665\n",
       "Utah                                              0.012586\n",
       "Hawaii                                            0.009937\n",
       "U.S. Pacific Trust Territories and Possessions    0.002513\n",
       "Name: OriginStateName, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the proportion of flights by origin state that had NaN delay values\n",
    "(delay_df[delay_df.ArrDel15.isna()].OriginStateName.value_counts() /\\\n",
    "delay_df.OriginStateName.value_counts()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f518081",
   "metadata": {},
   "source": [
    "Here we can see that there is indeed a difference in the degree to which each state's flights have missing values. However, the vast majority of these values are of the same order of magnitude. This, coupled with the fact that only 2% of rows have missing values suggests that it may be safer to remove these rows outright than to impute them.\n",
    "\n",
    "We can further inspect this fact by looking at the proportion of each month's flights that were missing delay information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "961c26de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.063902\n",
       "2     0.045524\n",
       "6     0.033831\n",
       "8     0.027451\n",
       "12    0.026640\n",
       "4     0.025849\n",
       "5     0.022225\n",
       "7     0.020855\n",
       "3     0.017957\n",
       "9     0.017518\n",
       "10    0.010126\n",
       "11    0.007594\n",
       "Name: Month, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting the proportion of flights by origin state that had NaN delay values\n",
    "(delay_df[delay_df.ArrDel15.isna()].Month.value_counts() /\\\n",
    "delay_df.Month.value_counts()).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa09093",
   "metadata": {},
   "source": [
    "Here too we can see a difference in missing values by month, but never more than an order of magnitude's worth of difference.\n",
    "\n",
    "When considering the fact that the missing data points are not extremely different from the rest of the dataset and that they make up only 2% of the data's rows, we can conclude that removing these rows would have a neglegible effect on how well the dataset represents the real world.\n",
    "\n",
    "As such, we can safely drop them in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b9307e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows of data with NaN in the target delay column (ArrDel15)\n",
    "delay_df = delay_df.dropna(subset=\"ArrDel15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c04bc1",
   "metadata": {},
   "source": [
    "With the rows that contained `NaN` values for delay now addressed we can inspect the dataset once more to see if there are any `NaN`s remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7b49dc49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the total number of NaNs in the trimmed dataset\n",
    "delay_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf9cfb1",
   "metadata": {},
   "source": [
    "In doing so, we can confirm that our dataset has been completely cleaning of missing values and move on to correcting our dataset's data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb7776b",
   "metadata": {},
   "source": [
    "### Cleaning Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc342141",
   "metadata": {},
   "source": [
    "Now that our dataset has been cleaned of meaningless NaN values, we must inspect the columns of our data to ensure that they are stored as the correct data type. Incorrect data types can cause our flight delay model to interpret numeric data as words, interpret dates as text, or simply fail to interpret data altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9af639ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Year                                 int64\n",
       "Quarter                              int64\n",
       "Month                                int64\n",
       "DayofMonth                           int64\n",
       "DayOfWeek                            int64\n",
       "FlightDate                          object\n",
       "Reporting_Airline                   object\n",
       "DOT_ID_Reporting_Airline             int64\n",
       "IATA_CODE_Reporting_Airline         object\n",
       "Tail_Number                         object\n",
       "Flight_Number_Reporting_Airline      int64\n",
       "OriginAirportID                      int64\n",
       "OriginAirportSeqID                   int64\n",
       "OriginCityMarketID                   int64\n",
       "Origin                              object\n",
       "OriginCityName                      object\n",
       "OriginState                         object\n",
       "OriginStateFips                      int64\n",
       "OriginStateName                     object\n",
       "OriginWac                            int64\n",
       "DestAirportID                        int64\n",
       "DestAirportSeqID                     int64\n",
       "DestCityMarketID                     int64\n",
       "Dest                                object\n",
       "DestCityName                        object\n",
       "DestState                           object\n",
       "DestStateFips                        int64\n",
       "DestStateName                       object\n",
       "DestWac                              int64\n",
       "CRSDepTime                           int64\n",
       "DepTime                            float64\n",
       "DepDelay                           float64\n",
       "DepDelayMinutes                    float64\n",
       "DepDel15                           float64\n",
       "DepartureDelayGroups               float64\n",
       "DepTimeBlk                          object\n",
       "TaxiOut                            float64\n",
       "WheelsOff                          float64\n",
       "WheelsOn                           float64\n",
       "TaxiIn                             float64\n",
       "CRSArrTime                           int64\n",
       "ArrTime                            float64\n",
       "ArrDelay                           float64\n",
       "ArrDelayMinutes                    float64\n",
       "ArrDel15                           float64\n",
       "ArrivalDelayGroups                 float64\n",
       "ArrTimeBlk                          object\n",
       "Cancelled                          float64\n",
       "Diverted                           float64\n",
       "CRSElapsedTime                     float64\n",
       "ActualElapsedTime                  float64\n",
       "AirTime                            float64\n",
       "Flights                            float64\n",
       "Distance                           float64\n",
       "DistanceGroup                        int64\n",
       "DivAirportLandings                   int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listing data types for each column\n",
    "delay_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313cbfc9",
   "metadata": {},
   "source": [
    "When comparing these data types to the data dictionary provided by the BTS [here](https://www.transtats.bts.gov/Fields.asp?gnoyr_VQ=FGJ), we can see that all but one of these columns contain the correct data type.\n",
    "\n",
    "While the vast majority of our data is correct, the `FlightDate` column is being represented as a string of text rather than as a date. In order to better represent the data in that column and prepare it for conversion to a direct numeric format if it is chosen for use in model training, this column should be converted to the datetime data type.\n",
    "\n",
    "This is accomplished in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa7850aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting flight date strings to datetime format\n",
    "delay_df.FlightDate = pd.to_datetime(delay_df.FlightDate, format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cbfc1f",
   "metadata": {},
   "source": [
    "### Saving Cleaned Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe8da99",
   "metadata": {},
   "source": [
    "\n",
    "With our dataset fully collected and cleaned, it is now ready to be saved and used for EDA and pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "920a2f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_df.to_pickle('./data/cleaned_aviation_data')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
